{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06aad80a-a9db-486a-8a5e-c20d248aafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure the current working directory is on the path\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c077b74a-e0fa-4ede-a52d-ed743b003d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawlee import Glob\n",
    "from crawlee.crawlers._beautifulsoup._beautifulsoup_crawler import BeautifulSoupCrawler, BeautifulSoupCrawlingContext\n",
    "from crawlee import EnqueueStrategy\n",
    "from crawlee.configuration import Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be29db7-611c-4b11-be79-ddc78d416c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = BeautifulSoupCrawler(\n",
    "    configuration=Configuration(\n",
    "        persist_storage=False,\n",
    "        purge_on_start=True,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f7e48d-9a22-4daa-9bf9-f5ee2c6b872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@crawler.router.default_handler\n",
    "async def request_handler(context: BeautifulSoupCrawlingContext) -> None:\n",
    "    context.log.info(f'Processing {context.request.url} ...')\n",
    "    # Enqueue links without specifying a strategy\n",
    "    await context.enqueue_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeeb76d7-b053-4e85-b226-b0ec96915c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawlee.storages import RequestQueue\n",
    "\n",
    "request_provider = await RequestQueue.open()\n",
    "await request_provider.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef87fa43-7bce-48a8-a2c3-16febd6b4343",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Storage with provided ID was not found (default).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/crawlee-python/src/crawlee/storages/_creation_management.py:90\u001b[39m, in \u001b[36m_rm_from_cache_by_id\u001b[39m\u001b[34m(storage_class, id)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(storage_class, RequestQueue):\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43m_cache_rq_by_id\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: 'default'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[38;5;28;01mawait\u001b[39;00m crawler.run([\u001b[33m'\u001b[39m\u001b[33mhttps://11-19-inject-broken-links.docs-7kl.pages.dev\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      2\u001b[39m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/crawlee-python/src/crawlee/crawlers/_basic/_basic_crawler.py:552\u001b[39m, in \u001b[36mBasicCrawler.run\u001b[39m\u001b[34m(self, requests, purge_request_queue)\u001b[39m\n\u001b[32m    550\u001b[39m     request_manager = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_request_manager()\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m purge_request_queue \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(request_manager, RequestQueue):\n\u001b[32m--> \u001b[39m\u001b[32m552\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m request_manager.drop()\n\u001b[32m    553\u001b[39m         \u001b[38;5;28mself\u001b[39m._request_manager = \u001b[38;5;28;01mawait\u001b[39;00m RequestQueue.open()\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m requests \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/crawlee-python/src/crawlee/storages/_request_queue.py:188\u001b[39m, in \u001b[36mRequestQueue.drop\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# Delete the storage from the underlying client and remove it from the cache\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._resource_client.delete()\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m \u001b[43mremove_storage_from_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage_class\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/crawlee-python/src/crawlee/storages/_creation_management.py:190\u001b[39m, in \u001b[36mremove_storage_from_cache\u001b[39m\u001b[34m(storage_class, id, name)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Remove a storage from cache by ID or name.\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[43m_rm_from_cache_by_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name:\n\u001b[32m    193\u001b[39m     _rm_from_cache_by_name(storage_class=storage_class, name=name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/crawlee-python/src/crawlee/storages/_creation_management.py:94\u001b[39m, in \u001b[36m_rm_from_cache_by_id\u001b[39m\u001b[34m(storage_class, id)\u001b[39m\n\u001b[32m     92\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnknown storage class: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstorage_class.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mStorage with provided ID was not found (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Storage with provided ID was not found (default)."
     ]
    }
   ],
   "source": [
    "results = await crawler.run(['https://11-19-inject-broken-links.docs-7kl.pages.dev'])\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (crawlee-env)",
   "language": "python",
   "name": "crawlee-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
